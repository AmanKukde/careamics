{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Noise2Void model\n",
    "\n",
    "Both the CARE network and Noise2Noise network you trained in part 1 and 2 require that you acquire additional data for the purpose of denoising. For CARE we used a paired acquisition with high SNR, for Noise2Noise we had paired noisy acquisitions. We will now train a Noise2Void network from single noisy images.\n",
    "\n",
    "This notebook uses a single image from the SEM data from the Noise2Noise notebook, but as you'll see in Task 3.1 if you brought your own raw data you should adapt the notebook to use that instead.\n",
    "\n",
    "We use the [Careamics](https://careamics.github.io) library"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\\\"> Set your kernel to \n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"><h3>Task 2.2: Bla</h3>\n",
    "    \n",
    "This notebook uses a single image from the SEM data from the Noise2Noise notebook.\n",
    "\n",
    "If you brought your own raw data, use that instead! The only requirement is that the noise in your data is pixel-independent and zero-mean. If you're unsure whether your data fulfills that requirement or you don't yet understand why it is necessary ask one of us to discuss!\n",
    "\n",
    "If you don't have suitable data of your own, feel free to find some online or ask your fellow course participants. You can however also stick with the SEM data provided here and compare the results to what you achieved with Noise2Noise in the previous part.\n",
    "\n",
    "\n",
    "</div>\n",
    "\n",
    "![diff_costs](static/diff_costs.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2px;\"><div class=\"alert alert-block alert-success\"><h1>Checkpoint 1</h1>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import tifffile\n",
    "from careamics_portfolio import PortfolioManager\n",
    "\n",
    "from careamics import CAREamist\n",
    "from careamics.config import (\n",
    "    create_n2v_training_configuration,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1. Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore portfolio\n",
    "portfolio = PortfolioManager()\n",
    "print(portfolio.denoising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download files # TODO File should be reused from previous exercise\n",
    "root_path = Path(\"./data\")\n",
    "files = portfolio.denoising.N2V_SEM.download(root_path)\n",
    "print(f\"List of downloaded files: {files}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "train_image = tifffile.imread(files[0])\n",
    "print(f\"Train image shape: {train_image.shape}\")\n",
    "plt.imshow(train_image, cmap=\"gray\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_image = tifffile.imread(files[1])\n",
    "print(f\"Validation image shape: {val_image.shape}\")\n",
    "plt.imshow(val_image, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "\n",
    "data_path = Path(root_path / \"n2v_sem\")\n",
    "train_path = data_path / \"train\"\n",
    "val_path = data_path / \"val\"\n",
    "\n",
    "train_path.mkdir(parents=True, exist_ok=True)\n",
    "val_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shutil.copy(root_path / files[0], train_path / \"train_image.tif\")\n",
    "shutil.copy(root_path / files[1], val_path / \"val_image.tif\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Create configuraion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = create_n2v_training_configuration(\n",
    "    experiment_name=\"LevitatingFrog\",\n",
    "    data_type=\"tiff\",\n",
    "    axes=\"YX\",\n",
    "    patch_size=[64, 64],\n",
    "    batch_size=128,\n",
    "    num_epochs=10,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize the Model\n",
    "\n",
    "Create a Pytorch Lightning module\n",
    "\n",
    "Please take as look at the [documentation](https://careamics.github.io) to see the full list of parameters and configuration options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = CAREamist(source=training_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3. Run training \n",
    "\n",
    "We need to specify the paths to training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.train(path_to_train_data=train_path, path_to_val_data=val_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = engine.predict(source=train_path, tile_size=(256, 256))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmcs_l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
